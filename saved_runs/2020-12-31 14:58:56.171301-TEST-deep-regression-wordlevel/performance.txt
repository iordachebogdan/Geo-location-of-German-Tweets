Fitting text vectorizer...
Building model...
99.99% coverage from Word2Vec
2020-12-31 15:06:36.618241: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2020-12-31 15:06:36.618713: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200000000 Hz
Epoch 1/20
2020-12-31 15:06:41.484925: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2020-12-31 15:06:42.026103: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
1412/1412 [==============================] - 66s 42ms/step - loss: 3.5602 - val_loss: 0.5791

Epoch 00001: val_loss improved from inf to 0.57912, saving model to checkpoints/best.h5
Epoch 2/20
1412/1412 [==============================] - 58s 41ms/step - loss: 0.9542 - val_loss: 0.8527

Epoch 00002: val_loss did not improve from 0.57912
Epoch 3/20
1412/1412 [==============================] - 59s 42ms/step - loss: 0.7210 - val_loss: 1.1221

Epoch 00003: val_loss did not improve from 0.57912
Epoch 4/20
1412/1412 [==============================] - 59s 42ms/step - loss: 0.6848 - val_loss: 1.0101

Epoch 00004: val_loss did not improve from 0.57912
Epoch 5/20
1412/1412 [==============================] - 59s 42ms/step - loss: 0.6474 - val_loss: 0.5287

Epoch 00005: val_loss improved from 0.57912 to 0.52866, saving model to checkpoints/best.h5
Epoch 6/20
1412/1412 [==============================] - 59s 42ms/step - loss: 0.6130 - val_loss: 0.5713

Epoch 00006: val_loss did not improve from 0.52866
Epoch 7/20
1412/1412 [==============================] - 59s 42ms/step - loss: 0.6173 - val_loss: 0.5110

Epoch 00007: val_loss improved from 0.52866 to 0.51096, saving model to checkpoints/best.h5
Epoch 8/20
1412/1412 [==============================] - 59s 42ms/step - loss: 0.5822 - val_loss: 0.7272

Epoch 00008: val_loss did not improve from 0.51096
Epoch 9/20
1412/1412 [==============================] - 59s 42ms/step - loss: 0.5834 - val_loss: 0.5911

Epoch 00009: val_loss did not improve from 0.51096
Epoch 10/20
1412/1412 [==============================] - 59s 42ms/step - loss: 0.5491 - val_loss: 0.8604

Epoch 00010: val_loss did not improve from 0.51096
Epoch 11/20
1412/1412 [==============================] - 59s 42ms/step - loss: 0.5238 - val_loss: 0.4869

Epoch 00011: val_loss improved from 0.51096 to 0.48688, saving model to checkpoints/best.h5
Epoch 12/20
1412/1412 [==============================] - 59s 42ms/step - loss: 0.5630 - val_loss: 0.7143

Epoch 00012: val_loss did not improve from 0.48688
Epoch 13/20
1412/1412 [==============================] - 59s 42ms/step - loss: 0.5417 - val_loss: 0.5845

Epoch 00013: val_loss did not improve from 0.48688
Epoch 14/20
1412/1412 [==============================] - 59s 42ms/step - loss: 0.5044 - val_loss: 0.7134

Epoch 00014: val_loss did not improve from 0.48688
Epoch 15/20
1412/1412 [==============================] - 59s 42ms/step - loss: 0.5451 - val_loss: 0.4808

Epoch 00015: val_loss improved from 0.48688 to 0.48085, saving model to checkpoints/best.h5
Epoch 16/20
1412/1412 [==============================] - 59s 42ms/step - loss: 0.4746 - val_loss: 0.5825

Epoch 00016: val_loss did not improve from 0.48085
Epoch 17/20
1412/1412 [==============================] - 59s 42ms/step - loss: 0.4745 - val_loss: 0.5133

Epoch 00017: val_loss did not improve from 0.48085
Epoch 18/20
1412/1412 [==============================] - 59s 42ms/step - loss: 0.4671 - val_loss: 0.5153

Epoch 00018: val_loss did not improve from 0.48085
Epoch 19/20
1412/1412 [==============================] - 59s 42ms/step - loss: 0.4293 - val_loss: 0.5184

Epoch 00019: val_loss did not improve from 0.48085
Epoch 20/20
1412/1412 [==============================] - 59s 42ms/step - loss: 0.4319 - val_loss: 0.5123

Epoch 00020: val_loss did not improve from 0.48085
Epoch 00020: early stopping
1412/1412 [==============================] - 24s 16ms/step
191/191 [==============================] - 5s 16ms/step
197/197 [==============================] - 5s 16ms/step
Training model for LONG
Fitting text vectorizer...
Building model...
99.99% coverage from Word2Vec
Epoch 1/20
1412/1412 [==============================] - 67s 43ms/step - loss: 1.1543 - val_loss: 0.5631

Epoch 00001: val_loss improved from inf to 0.56310, saving model to checkpoints/best.h5
Epoch 2/20
1412/1412 [==============================] - 59s 42ms/step - loss: 0.5939 - val_loss: 0.5341

Epoch 00002: val_loss improved from 0.56310 to 0.53410, saving model to checkpoints/best.h5
Epoch 3/20
1412/1412 [==============================] - 59s 42ms/step - loss: 0.5465 - val_loss: 0.5832

Epoch 00003: val_loss did not improve from 0.53410
Epoch 4/20
1412/1412 [==============================] - 59s 42ms/step - loss: 0.5296 - val_loss: 0.5084

Epoch 00004: val_loss improved from 0.53410 to 0.50837, saving model to checkpoints/best.h5
Epoch 5/20
1412/1412 [==============================] - 59s 42ms/step - loss: 0.4977 - val_loss: 0.5125

Epoch 00005: val_loss did not improve from 0.50837
Epoch 6/20
1412/1412 [==============================] - 59s 42ms/step - loss: 0.6231 - val_loss: 0.5076

Epoch 00006: val_loss improved from 0.50837 to 0.50760, saving model to checkpoints/best.h5
Epoch 7/20
1412/1412 [==============================] - 59s 42ms/step - loss: 0.6367 - val_loss: 0.5489

Epoch 00007: val_loss did not improve from 0.50760
Epoch 8/20
1412/1412 [==============================] - 59s 42ms/step - loss: 0.5224 - val_loss: 0.5449

Epoch 00008: val_loss did not improve from 0.50760
Epoch 9/20
1412/1412 [==============================] - 59s 42ms/step - loss: 0.4878 - val_loss: 0.5585

Epoch 00009: val_loss did not improve from 0.50760
Epoch 10/20
1412/1412 [==============================] - 60s 42ms/step - loss: 0.4493 - val_loss: 0.6331

Epoch 00010: val_loss did not improve from 0.50760
Epoch 11/20
1412/1412 [==============================] - 59s 42ms/step - loss: 0.4202 - val_loss: 0.5278

Epoch 00011: val_loss did not improve from 0.50760
Epoch 00011: early stopping
1412/1412 [==============================] - 25s 16ms/step
191/191 [==============================] - 5s 17ms/step
197/197 [==============================] - 5s 17ms/step
TRAIN: 0.38798697570457674
VAL: 0.4942254613205431