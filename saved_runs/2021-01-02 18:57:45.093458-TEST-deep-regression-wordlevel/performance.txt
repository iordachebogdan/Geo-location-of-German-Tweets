Fitting text vectorizer...
Building model...
99.99% coverage from Word2Vec
2021-01-02 19:03:21.839242: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-01-02 19:03:21.839702: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200000000 Hz
Epoch 1/20
2021-01-02 19:03:26.792307: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2021-01-02 19:03:27.334803: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
1412/1412 [==============================] - 38s 21ms/step - loss: 2.5640 - val_loss: 0.8354

Epoch 00001: val_loss improved from inf to 0.83543, saving model to checkpoints/best.h5
Epoch 2/20
1412/1412 [==============================] - 28s 20ms/step - loss: 0.7124 - val_loss: 0.5312

Epoch 00002: val_loss improved from 0.83543 to 0.53120, saving model to checkpoints/best.h5
Epoch 3/20
1412/1412 [==============================] - 28s 20ms/step - loss: 0.6043 - val_loss: 0.6887

Epoch 00003: val_loss did not improve from 0.53120
Epoch 4/20
1412/1412 [==============================] - 28s 20ms/step - loss: 0.6312 - val_loss: 0.7472

Epoch 00004: val_loss did not improve from 0.53120
Epoch 5/20
1412/1412 [==============================] - 28s 20ms/step - loss: 0.5844 - val_loss: 0.7089

Epoch 00005: val_loss did not improve from 0.53120
Epoch 6/20
1412/1412 [==============================] - 28s 20ms/step - loss: 0.5801 - val_loss: 0.5925

Epoch 00006: val_loss did not improve from 0.53120
Epoch 7/20
1412/1412 [==============================] - 28s 20ms/step - loss: 0.5711 - val_loss: 0.5198

Epoch 00007: val_loss improved from 0.53120 to 0.51980, saving model to checkpoints/best.h5
Epoch 8/20
1412/1412 [==============================] - 28s 20ms/step - loss: 0.5528 - val_loss: 0.5571

Epoch 00008: val_loss did not improve from 0.51980
Epoch 9/20
1412/1412 [==============================] - 28s 20ms/step - loss: 0.5916 - val_loss: 0.6030

Epoch 00009: val_loss did not improve from 0.51980
Epoch 10/20
1412/1412 [==============================] - 28s 20ms/step - loss: 0.5976 - val_loss: 0.6259

Epoch 00010: val_loss did not improve from 0.51980
Epoch 11/20
1412/1412 [==============================] - 28s 20ms/step - loss: 0.5411 - val_loss: 0.7077

Epoch 00011: val_loss did not improve from 0.51980
Epoch 12/20
1412/1412 [==============================] - 28s 20ms/step - loss: 0.5372 - val_loss: 0.6376

Epoch 00012: val_loss did not improve from 0.51980
Epoch 00012: early stopping
1412/1412 [==============================] - 12s 7ms/step
191/191 [==============================] - 4s 8ms/step
197/197 [==============================] - 3s 8ms/step
Training model for LONG
Fitting text vectorizer...
Building model...
99.99% coverage from Word2Vec
Epoch 1/20
1412/1412 [==============================] - 36s 22ms/step - loss: 1.0666 - val_loss: 0.6429

Epoch 00001: val_loss improved from inf to 0.64291, saving model to checkpoints/best.h5
Epoch 2/20
1412/1412 [==============================] - 28s 20ms/step - loss: 0.6036 - val_loss: 0.6400

Epoch 00002: val_loss improved from 0.64291 to 0.63999, saving model to checkpoints/best.h5
Epoch 3/20
1412/1412 [==============================] - 28s 20ms/step - loss: 0.5424 - val_loss: 0.7227

Epoch 00003: val_loss did not improve from 0.63999
Epoch 4/20
1412/1412 [==============================] - 28s 20ms/step - loss: 0.5087 - val_loss: 0.6514

Epoch 00004: val_loss did not improve from 0.63999
Epoch 5/20
1412/1412 [==============================] - 28s 20ms/step - loss: 0.4983 - val_loss: 0.5196

Epoch 00005: val_loss improved from 0.63999 to 0.51963, saving model to checkpoints/best.h5
Epoch 6/20
1412/1412 [==============================] - 28s 20ms/step - loss: 0.4689 - val_loss: 0.5176

Epoch 00006: val_loss improved from 0.51963 to 0.51758, saving model to checkpoints/best.h5
Epoch 7/20
1412/1412 [==============================] - 28s 20ms/step - loss: 0.4440 - val_loss: 0.6329

Epoch 00007: val_loss did not improve from 0.51758
Epoch 8/20
1412/1412 [==============================] - 28s 20ms/step - loss: 0.4277 - val_loss: 0.5513

Epoch 00008: val_loss did not improve from 0.51758
Epoch 9/20
1412/1412 [==============================] - 28s 20ms/step - loss: 0.3938 - val_loss: 0.5359

Epoch 00009: val_loss did not improve from 0.51758
Epoch 10/20
1412/1412 [==============================] - 28s 20ms/step - loss: 0.3840 - val_loss: 0.5182

Epoch 00010: val_loss did not improve from 0.51758
Epoch 11/20
1412/1412 [==============================] - 28s 20ms/step - loss: 0.3663 - val_loss: 0.5416

Epoch 00011: val_loss did not improve from 0.51758
Epoch 00011: early stopping
1412/1412 [==============================] - 12s 7ms/step
191/191 [==============================] - 3s 8ms/step
197/197 [==============================] - 3s 8ms/step
TRAIN: 0.45490354877447836
VAL: 0.5186918874240098