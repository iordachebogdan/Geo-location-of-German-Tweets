{
    "method": "regression",
    "word2vec": {
        "emb_size": 600,
        "min_count": 1,
        "iter": 20,
        "sg": 1
    },
    "model": {
        "vocab_size": 20000,
        "embedding_size": 600,
        "hidden_dim": 600,
        "clf_dim": [
            1024,
            1024
        ],
        "dropout_p": 0.3,
        "optimizer": "adam",
        "loss": "MAE"
    },
    "training": {
        "epochs": 50,
        "batch_size": 16,
        "es": 50
    }
}